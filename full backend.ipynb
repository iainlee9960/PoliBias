{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import models\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import PyPDF2\n",
    "\n",
    "from youtube_transcript_api import YouTubeTranscriptApi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def url_to_string(url):\n",
    "    res = requests.get(url)\n",
    "    html_page = res.content\n",
    "    soup = BeautifulSoup(html_page, 'html.parser')\n",
    "    text = soup.find_all(text=True)\n",
    "    #print(set([t.parent.name for t in text]))\n",
    "    txt = ''\n",
    "    blacklist = [\n",
    "         '[document]',\n",
    "         'a',\n",
    "         'body',\n",
    "         #'cite',\n",
    "         #'div',\n",
    "         #'h1',\n",
    "         'h2',\n",
    "         'h3',\n",
    "         'h4',\n",
    "         'li',\n",
    "         'link',\n",
    "         #'p',\n",
    "         'script',\n",
    "         #'span',\n",
    "         'style',\n",
    "         #'title'\n",
    "    ]\n",
    "    for t in text:\n",
    "        if t.parent.name not in blacklist:\n",
    "            txt += '{} '.format(t)\n",
    "    #formatting        \n",
    "    txt = txt.replace(\"\\n\",\"\")\n",
    "    txt = \" \".join(txt.split())\n",
    "    return txt\n",
    "\n",
    "def txt_to_string(path):\n",
    "    txt = open(pathStr, 'r', encoding = 'utf8').read()\n",
    "    txt = txt.replace(\"\\n\",\"\")\n",
    "    txt = \" \".join(txt.split())\n",
    "    return txt\n",
    "\n",
    "def pdf_to_string(path):\n",
    "    pdffileobj=open(path,'rb')\n",
    "    pdfreader=PyPDF2.PdfFileReader(pdffileobj)\n",
    "    x=pdfreader.numPages\n",
    "    pageobj=pdfreader.getPage(x-1)\n",
    "    txt=pageobj.extractText()\n",
    "    #txt = txt.replace(\"\\n\",\"\")\n",
    "    #txt = \" \".join(txt.split())\n",
    "    return txt\n",
    "\n",
    "def youtube_to_string(link):\n",
    "    link = link.replace('https://www.youtube.com/watch?v=', '')\n",
    "    transcription_dict = YouTubeTranscriptApi.get_transcript(link)\n",
    "    txt = ''\n",
    "    for i in transcription_dict:\n",
    "        txt=txt+i['text']\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "    def __init__(self, string):\n",
    "        self.text = string\n",
    "        self.bias = self.predict()\n",
    "\n",
    "    def preprocessData(self):\n",
    "        string = [self.text]\n",
    "        max_features = 50000\n",
    "        max_length = 500\n",
    "        tokenizer = Tokenizer(num_words=50000)\n",
    "        tokenizer.fit_on_texts(string)\n",
    "        tokens = tokenizer.texts_to_sequences(string)\n",
    "        return preprocessing.sequence.pad_sequences(tokens, max_length)\n",
    "\n",
    "    def predict(self):\n",
    "        political_model = models.load_model('/home/iain/Deep learning/CongAppChallenge/models/PoliticalBias.h5')\n",
    "        political_model.summary()\n",
    "        data = np.asarray(self.preprocessData()).astype('float32')\n",
    "        #print(data.shape)\n",
    "        prediction = political_model.predict(data)[0][0]\n",
    "        prediction_str = ''\n",
    "        if prediction>=0 and prediction<=.2:\n",
    "            prediction_str = 'super conservative'\n",
    "        elif prediction>.2 and prediction<.4:\n",
    "            prediction_str = 'moderately conservative'\n",
    "        elif prediction>=.4 and prediction<=.6:\n",
    "            prediction_str = 'moderate'\n",
    "        elif prediction>.6 and prediction<.8:\n",
    "            prediction_str = 'moderately liberal'\n",
    "        else:\n",
    "            prediction_str ='super liberal'\n",
    "        return [prediction, prediction_str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = url_to_string('https://www.politico.com/news/2020/05/26/trump-campaign-lewandowski-bossie-283089')\n",
    "data = 'hello'\n",
    "network = Network(data)\n",
    "print(network.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(0, url)\n",
    "#predict(1, txt_path)\n",
    "#predict(2, pdf_path)\n",
    "#predict(3, youtube_link)\n",
    "#predict(4, string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "graph = tf.compat.v1.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'theano'\n",
    "import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(keras.backend.backend())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
